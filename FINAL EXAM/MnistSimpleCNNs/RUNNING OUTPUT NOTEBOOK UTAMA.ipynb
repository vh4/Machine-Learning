{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final exam mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#training data mnist for model M5 python\n",
        "\n",
        "#Paper url is https://arxiv.org/abs/2008.10400.\n",
        "\n",
        "#In paper, we propose simple models classifying MNIST called M3, M5, M7 following kernel size."
      ],
      "metadata": {
        "id": "rV2Cui5UHR98"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# terlalu banyak epochs membutuhkan banyak waktu, maka akan saya kurangi epochs nya. dan juga akurasi\n",
        "# dengan 2 epochs saja sudah bagus 98%."
      ],
      "metadata": {
        "id": "ag5-a7eXbDFR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################   check baca dataset MNIST IMAGE DALAM BENTUK NILAI ##########################\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f = open('/content/data/MNIST/raw/train-images-idx3-ubyte', 'rb')\n",
        "xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "f.close()\n",
        "\n",
        "print(xs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43C64sOnpZs-",
        "outputId": "101b534d-6517-48d1-abb1-251b1920a8bd"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47040000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.reshape(xs, (-1, 28, 28))\n",
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "297yML4RsgR4",
        "outputId": "6e56de2d-4477-4442-f108-0011a9ecf4c7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3yRRAoruEIK",
        "outputId": "4d71106e-9a5e-4f21-b637-f3fd612b6813"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(images[0]) ######## lihat nilai array dari mnis diubah ke gambar terlihat jelas."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "LqVJ76sVsv21",
        "outputId": "ce9261c3-56f5-4115-f19f-34552df142d7"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd21a03ad10>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########################   CHECK APAKAH ADA NILAI 1, JIKA ADA MAKA BERARTI ITU ADALAH IMAGE #####################\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(xs, columns=['array_image'])\n",
        "print(df.loc[df['array_image'] == 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pd9epT0qDz3",
        "outputId": "746e1192-a818-4426-ee80-e7575e6e3175"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          array_image\n",
            "290                 1\n",
            "381                 1\n",
            "8303                1\n",
            "11127               1\n",
            "17764               1\n",
            "...               ...\n",
            "47034101            1\n",
            "47035510            1\n",
            "47036376            1\n",
            "47036382            1\n",
            "47037514            1\n",
            "\n",
            "[22896 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python code/datasets.py"
      ],
      "metadata": {
        "id": "3dNgSPecpMvV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 code/train.py --seed=0 --trial=2  --gpu=0 --epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs3pSLpIbLLl",
        "outputId": "eb7d8e3f-1e58-412d-f7f0-111061517a61"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:992: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.835055\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.677406\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.447411\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.381477\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.337774\n",
            "Best accuracy! correct images:  9872\n",
            "\n",
            "Test set: Average loss: 0.1571, Accuracy: 9872/10000 (98.72%) (best: 98.72%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.320439\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.243780\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.264489\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.151042\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.215020\n",
            "\n",
            "Test set: Average loss: 0.1412, Accuracy: 9835/10000 (98.35%) (best: 98.72%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.105091\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.102101\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.147225\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.156958\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.096310\n",
            "Best accuracy! correct images:  9936\n",
            "\n",
            "Test set: Average loss: 0.0507, Accuracy: 9936/10000 (99.36%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.069268\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.099156\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.086732\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.115401\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.113193\n",
            "\n",
            "Test set: Average loss: 0.0496, Accuracy: 9909/10000 (99.09%) (best: 99.36%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.103340\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.055776\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.117868\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.114982\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.063521\n",
            "Best accuracy! correct images:  9942\n",
            "\n",
            "Test set: Average loss: 0.0409, Accuracy: 9942/10000 (99.42%) (best: 99.42%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 24, 24]             800\n",
            "       BatchNorm2d-2           [-1, 32, 24, 24]              64\n",
            "            Conv2d-3           [-1, 64, 20, 20]          51,200\n",
            "       BatchNorm2d-4           [-1, 64, 20, 20]             128\n",
            "            Conv2d-5           [-1, 96, 16, 16]         153,600\n",
            "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
            "            Conv2d-7          [-1, 128, 12, 12]         307,200\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "            Conv2d-9            [-1, 160, 8, 8]         512,000\n",
            "      BatchNorm2d-10            [-1, 160, 8, 8]             320\n",
            "           Linear-11                   [-1, 10]         102,400\n",
            "      BatchNorm1d-12                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,128,180\n",
            "Trainable params: 1,128,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 4.30\n",
            "Estimated Total Size (MB): 5.79\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.773786\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.620557\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.498558\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.368061\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.292252\n",
            "Best accuracy! correct images:  9888\n",
            "\n",
            "Test set: Average loss: 0.1317, Accuracy: 9888/10000 (98.88%) (best: 98.88%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.224838\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.223490\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.181320\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.224687\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.158873\n",
            "Best accuracy! correct images:  9896\n",
            "\n",
            "Test set: Average loss: 0.1095, Accuracy: 9896/10000 (98.96%) (best: 98.96%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.131590\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.128995\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.092110\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.149985\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.145483\n",
            "Best accuracy! correct images:  9928\n",
            "\n",
            "Test set: Average loss: 0.0604, Accuracy: 9928/10000 (99.28%) (best: 99.28%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.141492\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.123821\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.093057\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.090780\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.104661\n",
            "Best accuracy! correct images:  9952\n",
            "\n",
            "Test set: Average loss: 0.0345, Accuracy: 9952/10000 (99.52%) (best: 99.52%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.134800\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.061522\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.055086\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.120983\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.103711\n",
            "\n",
            "Test set: Average loss: 0.0475, Accuracy: 9920/10000 (99.20%) (best: 99.52%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters:\n",
        "\n",
        "#seed : random seed number\n",
        "\n",
        "#trial : the number of trial. When previous trial is end, add present trial number to seed number.\n",
        "\n",
        "#Ex) seed=0 trial=10 ⇒ execute seed 0~9\n",
        "\n",
        "#kernel_size : kernel size of model. You can select the model following this parameter.\n",
        "\n",
        "#gpu : gpu number. You can use only one gpu during training in this code, but can select gpu when you training.\n",
        "\n",
        "#logdir : save directory address name. It makes a sub-directory using that name at logs directory."
      ],
      "metadata": {
        "id": "Z3At9Xd0hnkT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 code/test.py  --seed=0 --trial=2 --kernel_size=5 "
      ],
      "metadata": {
        "id": "oHSxUp9thuKt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test.py loads model saving files and make wrong image number list for each seed."
      ],
      "metadata": {
        "id": "zwSZyPAQh4MY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#homo_ensemble.py loads wrong image number list files of same model saving during \n",
        "#executing test.py. And then calculate the accuracy of ensemble model \n",
        "#through majority voting."
      ],
      "metadata": {
        "id": "n5XcFBXUmg15"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 code/homo_ensemble.py --kernel_size=5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAwCdSAkjNee",
        "outputId": "0e616f4c-6645-41a4-d13f-9bfdc4206e82"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   1   58   48   30   30\n",
            "   2   58   48   30   30\n",
            "   3   58   48   30   30\n",
            "   4   58   48   30   30\n",
            "   5   58   48   30   30\n",
            "   6   58   48   30   30\n",
            "   7   58   48   30   30\n",
            "   8   58   48   30   30\n",
            "   9   58   48   30   30\n",
            "  10   58   48   30   30\n",
            "  11   58   48   30   30\n",
            "  12   58   48   30   30\n",
            "  13   58   48   30   30\n",
            "  14   58   48   30   30\n",
            "  15   58   48   30   30\n",
            "  16   58   48   30   30\n",
            "  17   58   48   30   30\n",
            "  18   58   48   30   30\n",
            "  19   58   48   30   30\n",
            "  20   58   48   30   30\n",
            "  21   58   48   30   30\n",
            "  22   58   48   30   30\n",
            "  23   58   48   30   30\n",
            "  24   58   48   30   30\n",
            "  25   58   48   30   30\n",
            "  26   58   48   30   30\n",
            "  27   58   48   30   30\n",
            "  28   58   48   30   30\n",
            "  29   58   48   30   30\n",
            "  30   58   48   30   30\n",
            "  31   58   48   30   30\n",
            "  32   58   48   30   30\n",
            "  33   58   48   30   30\n",
            "  34   58   48   30   30\n",
            "  35   58   48   30   30\n",
            "  36   58   48   30   30\n",
            "  37   58   48   30   30\n",
            "  38   58   48   30   30\n",
            "  39   58   48   30   30\n",
            "  40   58   48   30   30\n",
            "  41   58   48   30   30\n",
            "  42   58   48   30   30\n",
            "  43   58   48   30   30\n",
            "  44   58   48   30   30\n",
            "  45   58   48   30   30\n",
            "  46   58   48   30   30\n",
            "  47   58   48   30   30\n",
            "  48   58   48   30   30\n",
            "  49   58   48   30   30\n",
            "  50   58   48   30   30\n",
            "  51   58   48   30   30\n",
            "  52   58   48   30   30\n",
            "  53   58   48   30   30\n",
            "  54   58   48   30   30\n",
            "  55   58   48   30   30\n",
            "  56   58   48   30   30\n",
            "  57   58   48   30   30\n",
            "  58   58   48   30   30\n",
            "  59   58   48   30   30\n",
            "  60   58   48   30   30\n",
            "  61   58   48   30   30\n",
            "  62   58   48   30   30\n",
            "  63   58   48   30   30\n",
            "  64   58   48   30   30\n",
            "  65   58   48   30   30\n",
            "  66   58   48   30   30\n",
            "  67   58   48   30   30\n",
            "  68   58   48   30   30\n",
            "  69   58   48   30   30\n",
            "  70   58   48   30   30\n",
            "  71   58   48   30   30\n",
            "  72   58   48   30   30\n",
            "  73   58   48   30   30\n",
            "  74   58   48   30   30\n",
            "  75   58   48   30   30\n",
            "  76   58   48   30   30\n",
            "  77   58   48   30   30\n",
            "  78   58   48   30   30\n",
            "  79   58   48   30   30\n",
            "  80   58   48   30   30\n",
            "  81   58   48   30   30\n",
            "  82   58   48   30   30\n",
            "  83   58   48   30   30\n",
            "  84   58   48   30   30\n",
            "  85   58   48   30   30\n",
            "  86   58   48   30   30\n",
            "  87   58   48   30   30\n",
            "  88   58   48   30   30\n",
            "  89   58   48   30   30\n",
            "  90   58   48   30   30\n",
            "  91   58   48   30   30\n",
            "  92   58   48   30   30\n",
            "  93   58   48   30   30\n",
            "  94   58   48   30   30\n",
            "  95   58   48   30   30\n",
            "  96   58   48   30   30\n",
            "  97   58   48   30   30\n",
            "  98   58   48   30   30\n",
            "  99   58   48   30   30\n",
            " 100   58   48   30   30\n",
            " 101   58   48   30   30\n",
            " 102   58   48   30   30\n",
            " 103   58   48   30   30\n",
            " 104   58   48   30   30\n",
            " 105   58   48   30   30\n",
            " 106   58   48   30   30\n",
            " 107   58   48   30   30\n",
            " 108   58   48   30   30\n",
            " 109   58   48   30   30\n",
            " 110   58   48   30   30\n",
            " 111   58   48   30   30\n",
            " 112   58   48   30   30\n",
            " 113   58   48   30   30\n",
            " 114   58   48   30   30\n",
            " 115   58   48   30   30\n",
            " 116   58   48   30   30\n",
            " 117   58   48   30   30\n",
            " 118   58   48   30   30\n",
            " 119   58   48   30   30\n",
            " 120   58   48   30   30\n"
          ]
        }
      ]
    }
  ]
}